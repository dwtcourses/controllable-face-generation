{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as fnn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from firelab.config import Config\n",
    "\n",
    "from visualize import random_interpolation, uniform_interpolation, visualization\n",
    "from utils import load_dataset\n",
    "from evaluation import fit_FC\n",
    "from modules import Autoencoder, Critic\n",
    "from train import train_acai, train_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ACAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please write `your path` where the folder with raw images is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ...\n",
    "DEVICE = ... # Probably 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebA(Dataset):\n",
    "    def __init__(self, path='/root/data/CelebA/img_align_celeba/', part='train'):\n",
    "        if part=='train':\n",
    "            self.data = [os.path.join(path, file) for file in os.listdir(path)][:182637]\n",
    "        else:\n",
    "            self.data = [os.path.join(path, file) for file in os.listdir(path)][182637:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(Image.open(self.data[idx]))\n",
    "    \n",
    "def make_dataloader(dataset, batch_size, image_size=4):\n",
    "    dataset.transform = transforms.Compose([\n",
    "                                            transforms.Resize((image_size, image_size)),                \n",
    "                                            transforms.RandomHorizontalFlip(),      \n",
    "                                            transforms.ToTensor()])\n",
    "    return DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = make_dataloader(CelebA(path = PATH), 64, image_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('CelebA64_256_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args =  {'dataset': 'MNIST',\n",
    "         'eval_each': 10,\n",
    "         'epochs': 101,\n",
    "         'log_dir': 'CelebA64_256_v2/',\n",
    "         'device': 'cuda:7',\n",
    "         'weight_decay': 1e-05,\n",
    "         'depth': 16,\n",
    "         'gamma': 0.2,\n",
    "         'lmbda': 0.5,\n",
    "         'batch_norm': False,\n",
    "         'batch_size': 64,\n",
    "         'colors': 3,\n",
    "         'latent_width': 4, # Bottleneck HW\n",
    "         'width': 128, # Means 4 downsampling blocks\n",
    "         'latent': 32, # Bottleneck channels\n",
    "         'n_classes': 10,\n",
    "         'advdepth': 16,\n",
    "         'lr': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = int(round(math.log(args['width'] // args['latent_width'], 2)))\n",
    "autoencoder = Autoencoder(scales=scales,depth=args['depth'],latent=args['latent'],colors=args['colors']).to(args['device'])\n",
    "critic = Critic(scales=scales, depth=args['advdepth'], latent=args['latent'], colors=args['colors']).to(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "opt_ae = optim.Adam(autoencoder.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "opt_c = optim.Adam(critic.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "losses = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define `Perceptual Loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh2sigmoid(batch):\n",
    "    return batch.div(2).add(0.5)\n",
    "\n",
    "class VGGExtractor(nn.Module):\n",
    "    def __init__(self, vgg):\n",
    "        super(VGGExtractor, self).__init__()\n",
    "        \n",
    "        mean = torch.FloatTensor([0.485, 0.456, 0.406])[None, :, None, None]\n",
    "        self.register_buffer('mean', mean)\n",
    "\n",
    "        std = torch.FloatTensor([0.229, 0.224, 0.225])[None, :, None, None]\n",
    "        self.register_buffer('std', std)\n",
    "        \n",
    "        self.relu0_1 = vgg[0:2]\n",
    "        self.relu1_1 = vgg[2:7]\n",
    "        self.relu2_1 = vgg[7:12]\n",
    "        self.relu3_1 = vgg[12:21]\n",
    "        self.relu4_1 = vgg[21:30]\n",
    "        \n",
    "    def forward(self, x, level=1):\n",
    "        x = (x - self.mean)/self.std\n",
    "        \n",
    "        extracted_featrues = []\n",
    "        for block in [self.relu0_1, self.relu1_1, self.relu2_1, self.relu3_1, self.relu4_1][:level]:\n",
    "            x = block(x)\n",
    "            extracted_featrues.append(x)\n",
    "            \n",
    "        return extracted_featrues\n",
    "    \n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        self.feature_exctracor = VGGExtractor(models.vgg19(pretrained=True).features).to(DEVICE)\n",
    "        self.feature_exctracor.eval();\n",
    "\n",
    "    def forward(self, inp1, inp2, level):\n",
    "        features1, features2 = self.feature_exctracor(inp1, level), self.feature_exctracor(inp2, level)\n",
    "        return [(features1[i] - features2[i]).pow(2).mean() for i in range(level)]\n",
    "    \n",
    "vgg_loss = VGGLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Training loop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 0', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 1', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 2', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 3', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 4', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 5', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 6', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 7', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 8', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 9', max=2853.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 10', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 11', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 12', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 13', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 14', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 15', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 16', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1549c3936f42c6971024363657216e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch: 17', max=2853.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOG_DIR = 'CelebA64_256_v2/'\n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    for index, X in tqdm(enumerate(train_loader), total=len(train_loader), leave=False, desc=f'Epoch: {epoch}'):\n",
    "        X = X.to(args['device'])\n",
    "        \n",
    "        alpha = 0.5 * torch.rand(args['batch_size'], 1, 1, 1).to(args['device'])\n",
    "\n",
    "        latent_code = autoencoder.encoder(X)\n",
    "        reconstruction = autoencoder.decoder(latent_code)\n",
    "\n",
    "        # Here we shift all objects in batch by 1\n",
    "        shifted_index = torch.arange(0, args['batch_size']) - 1\n",
    "        interpolated_code = latent_code + alpha * (latent_code[shifted_index] - latent_code)\n",
    "\n",
    "        # Decode interpolated latent code and calculate Critic's predictions\n",
    "        reconstruction_interpolated = autoencoder.decoder(interpolated_code)\n",
    "        alpha_reconstruction = critic(reconstruction_interpolated).reshape(args['batch_size'], 1, 1, 1)\n",
    "        \n",
    "        # Term1: Reconstruction loss\n",
    "        # Term2: Trying to fool the Critic via Lowering it's predicted values on interpolated samples\n",
    "        \n",
    "        reconstruction_loss = F.mse_loss(X, reconstruction)\n",
    "        critic_fooling_loss = (alpha_reconstruction**2).sum()\n",
    "        \n",
    "        perceptual1, perceptual2, perceptual3 = vgg_loss(X, reconstruction, 3)\n",
    "        \n",
    "        ae_loss = reconstruction_loss + (perceptual1 + perceptual2.mul(1/5) + perceptual2.mul(1/10))  + \\\n",
    "                  args['lmbda'] * critic_fooling_loss\n",
    "\n",
    "        # Term1: Critic is trying to guess actual alpha\n",
    "        # Term2: Critic is trying to assing \"high realistic score\" to samples which are linear interpolations (in data spcae)\n",
    "        #        of original images and their reconstructions. Thus we are trying to encode the information about real samples\n",
    "        #        to help Critic to distinguish between original and interpolated samples. (REGULARIZATION, optional)\n",
    "        #        In case if our AE is perfect, it is just the critic(X) -> 0, w.r.t. Critic parameters\n",
    "        \n",
    "        alpha_guessing_loss = F.mse_loss(alpha_reconstruction, alpha)\n",
    "        realistic_loss = (critic(args['gamma'] * X + (1 - args['gamma']) * reconstruction)**2).sum()\n",
    "        critic_loss = alpha_guessing_loss + realistic_loss\n",
    "        \n",
    "        # AE's parameters update\n",
    "        opt_ae.zero_grad()\n",
    "        ae_loss.backward(retain_graph=True)\n",
    "        opt_ae.step()\n",
    "\n",
    "        # Critic's parameters update\n",
    "        opt_c.zero_grad()\n",
    "        critic_loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Clip gradients of a Critic\n",
    "#         nn.utils.clip_grad_norm_(critic.parameters(), 4)\n",
    "        opt_c.step()\n",
    "        \n",
    "        # Store gradient norms\n",
    "    uniform_interpolation(autoencoder, train_loader, N=11, savepath=f'{LOG_DIR}{epoch}.png')\n",
    "    \n",
    "    torch.save(autoencoder.state_dict(), LOG_DIR + 'ae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'AE': autoencoder.state_dict(),\n",
    "            'Critic': critic.state_dict()},\n",
    "            'CelebA64_256_v2/acai.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
